{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import IPython\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchaudio'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eac0b528b302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchaudio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchaudio'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr= librosa.core.load(\"./please.wav\", 44100)\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "S_db = librosa.core.power_to_db(S)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True)\n",
    "librosa.display.specshow(S_db, y_axis='log', sr=sr, x_axis='time', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(\n",
    "\t\tself, \n",
    "\t\twake_word_path, \n",
    "\t\tbackground_sounds_root_path = \"D:/Storage/UrbanSound8K/audio/fold1\",\n",
    "\t\tmax_length = 3,\n",
    "\t\tsampling_rate = 44100 #44.1 Hz\n",
    "\t\t):\n",
    "\t\tself.wake_word_path = wake_word_path\n",
    "\t\tself.sampling_rate = sampling_rate\n",
    "\t\tself.background_sounds_root_path = background_sounds_root_path\n",
    "\t\tself.background_noise_sound_paths =  list(pathlib.Path(background_sounds_root_path).glob('*.wav'))\n",
    "\t\tself.generated_samples = []\n",
    "\n",
    "\t\tsample_size = sampling_rate * max_length\n",
    "\t\t\n",
    "\t\tself.wake_word, _ = librosa.core.load(self.wake_word_path, sr=sampling_rate)\n",
    "\t\tself.wake_word = np.pad(self.wake_word, (0, 2 * sampling_rate - len(self.wake_word)))\n",
    "\t\t\n",
    "\t\tif len(self.wake_word) > sample_size:\n",
    "\t\t\traise Exception(f\"Wake word size {len(self.wake_word)} bigger than the background noise max length {sample_size}\")\n",
    "\n",
    "\t\t#Spec Augment transforms\n",
    "\t\tself.transforms = nn.Sequential(\n",
    "\t\t\ttransforms.FrequencyMasking(freq_mask_param=2),\n",
    "\t\t\ttransforms.TimeMasking(time_mask_param=4)\n",
    "\t\t)\n",
    "\n",
    "\t\tfor idx, path in enumerate(self.background_noise_sound_paths[:500]):\n",
    "\t\t\ty, sr = librosa.core.load(path, sr=sampling_rate)\n",
    "\n",
    "\t\t\tif len(y) < sample_size:\n",
    "\t\t\t\ty = np.pad(y, (0, sample_size - len(y)))\n",
    "\t\t\telse:\n",
    "\t\t\t\ty = y[:sample_size]\n",
    "\n",
    "\t\t\ty_false = np.array(y, copy=True)\n",
    "\t\t\ty_true = y\n",
    "\n",
    "\t\t\tinterval = self._get_random_time_interval(len(self.wake_word), max_length * sampling_rate)\n",
    "\t\t\tself._overlay_wakeword(y_true[interval[0]:interval[1]], self.wake_word)\n",
    "\t\t\t# self._save_sound(y)\n",
    "\n",
    "\t\t\tS_true = librosa.feature.melspectrogram(y=y_true, sr=sr)\n",
    "\t\t\tS_db_true = librosa.core.power_to_db(S_true)\n",
    "\t\t\tS_db_true = self.transforms(torch.from_numpy(S_db_true))\n",
    "\n",
    "\t\t\tS_false = librosa.feature.melspectrogram(y=y_false, sr=sr)\n",
    "\t\t\tS_db_false = librosa.core.power_to_db(S_false)\n",
    "\t\t\tS_db_false = self.transforms(torch.from_numpy(S_db_false))\n",
    "\n",
    "\t\t\t# Labels for position detection of the wake word\n",
    "\t\t\t# label = np.zeros(sample_size)\n",
    "\t\t\t# label[interval[1]:interval[1] + 50] = 1\n",
    "\n",
    "\t\t\tself.generated_samples.append(\n",
    "\t\t\t\t(S_db_true.unsqueeze(dim=0).float(), torch.tensor([1]).float())\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tself.generated_samples.append(\n",
    "\t\t\t\t(S_db_false.unsqueeze(dim=0).float(), torch.tensor([0]).float())\n",
    "\t\t\t)\n",
    "\t\t\t\t\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn self.generated_samples[idx]\n",
    "\n",
    "\tdef _get_random_time_interval(self, interval_size, max_size):\n",
    "\t\tinterval_start = np.random.randint(low=0, high=max_size - interval_size)\n",
    "\t\tinterval_end = interval_start + interval_size\n",
    "\n",
    "\t\treturn interval_start, interval_end\n",
    "\n",
    "\tdef _overlay_wakeword(self, background, addition):\n",
    "\t\tbackground += addition\n",
    "\t\tbackground /= 2\n",
    "\n",
    "\tdef _save_sound(self, data, name=\"generated_file.wav\"):\n",
    "\t\tsf.write(name, data, self.sampling_rate)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 128, 259])\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"please.wav\")\n",
    "sample = dataset[0][0]\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakeWordCNNModel(nn.Module):\n",
    "\tdef __init__(self, output_size, training = True):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.training = training\n",
    "\n",
    "\t\tself.conv_block1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=1, out_channels=16, kernel_size=4, padding=4),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2),\n",
    "\t\t\tnn.BatchNorm2d(16),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(in_channels=16, out_channels=16, kernel_size=4, padding=4),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2),\n",
    "\t\t\tnn.BatchNorm2d(16),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.conv_block2 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, padding=4),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2),\n",
    "\t\t\tnn.BatchNorm2d(32),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, padding=4),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2),\n",
    "\t\t\tnn.BatchNorm2d(32),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True)\n",
    "\t\t)\n",
    "\n",
    "\n",
    "\t\tself.l1 = nn.Linear(7680, 256)\n",
    "\t\tself.l2 = nn.Linear(256, output_size)\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tout = self.conv_block1(input)\n",
    "\t\tout = self.conv_block2(out)\n",
    "\n",
    "\t\t# print(out.shape)\n",
    "\t\tout = out.view(out.size(0), -1)\n",
    "\n",
    "\t\tout = self.l1(out)\n",
    "\t\tout = F.leaky_relu(out)\n",
    "\n",
    "\t\tout = self.l2(out)\n",
    "\t\tout = F.sigmoid(out)\n",
    "\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "model = WakeWordCNNModel(output_size=1)\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(dataloader):\n",
    "#     data, labels = sample_batched\n",
    "\n",
    "#     model(data.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "WakeWordCNNModel(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(16, 16, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (l1): Linear(in_features=7680, out_features=256, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch [1] progress:   0%|          | 0/200 [00:00<?, ?it/s]Epoch 0/50\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "expected 2D or 3D input (got 4D input)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c4c012c135c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-9c7cc3b30eb0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_block1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_block2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# exponential_average_factor is set to self.momentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             raise ValueError('expected 2D or 3D input (got {}D input)'\n\u001b[1;32m--> 209\u001b[1;33m                              .format(input.dim()))\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected 2D or 3D input (got 4D input)"
     ]
    }
   ],
   "source": [
    "EARLY_STOPPING_PATIENCE = 3\n",
    "previous_epoch_loss = None\n",
    "early_stopping_counter = 0\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "loss_criterion = torch.nn.BCELoss(size_average = True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "training_dataset_size = len(dataset)\n",
    "num_epochs = 50\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    model = model.train()\n",
    "    training_loss = []\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "\n",
    "    for i, data in enumerate(tqdm(dataloader, desc=f\"Epoch [{epoch + 1}] progress\")):\n",
    "        x_batch, label_batch = data\n",
    "        x_batch, label_batch = x_batch.to(device), label_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "\n",
    "        loss = loss_criterion(outputs, label_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        preds =  torch.round(outputs)\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "        running_corrects += torch.sum(preds == label_batch.detach())\n",
    "#         print(preds)\n",
    "#         print(label_batch)\n",
    "#         break\n",
    "        training_loss.append(loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / training_dataset_size\n",
    "    epoch_acc = running_corrects.double() / training_dataset_size\n",
    "\n",
    "    print('Training step => Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc\n",
    "    ))\n",
    "\n",
    "    scheduler.step(epoch_acc)\n",
    "\n",
    "    if previous_epoch_loss is None:\n",
    "        previous_epoch_loss = epoch_loss\n",
    "    else:\n",
    "        if epoch_loss > previous_epoch_loss:\n",
    "            early_stopping_counter += 1\n",
    "            previous_epoch_loss = epoch_loss\n",
    "        else:\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "    if early_stopping_counter == EARLY_STOPPING_PATIENCE:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(wake_word_path, background_path=None, duration_seconds=3, wake_word_duration_seconds = 2, sampling_rate=44100):\n",
    "    sample_size = sampling_rate * duration_seconds\n",
    "    interval_size = sampling_rate * wake_word_duration_seconds\n",
    "\t\n",
    "    wake_word, _ = librosa.core.load(wake_word_path, sr=sampling_rate)\n",
    "    print(len(wake_word))\n",
    "    print(2 * sampling_rate)\n",
    "    if len(wake_word) < 2 * sampling_rate:\n",
    "        wake_word = np.pad(wake_word, (0, 2 * sampling_rate - len(wake_word)))\n",
    "    else:\n",
    "        wake_word = wake_word[: 2 * sampling_rate]\n",
    "\n",
    "    generated_sample = None\n",
    "    if background_path is not None:\n",
    "        generated_sample, _ = librosa.core.load(background_path, sr=sampling_rate)\n",
    "        if len(generated_sample) < sample_size:\n",
    "            generated_sample = np.pad(generated_sample, (0, sample_size - len(generated_sample)))\n",
    "        else:\n",
    "            generated_sample = generated_sample[:sample_size]\n",
    "    else:\n",
    "        generated_sample = np.zeros((sample_size))\n",
    "\n",
    "    interval_start = np.random.randint(low=0, high=sample_size - interval_size)\n",
    "    interval_end = interval_start + interval_size\n",
    "\n",
    "    generated_sample[interval_start:interval_end] += wake_word\n",
    "    generated_sample /= 2\n",
    "    return generated_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "WakeWordCNNModel(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(16, 16, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1), padding=(4, 4))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (l1): Linear(in_features=7680, out_features=256, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model = WakeWordCNNModel(output_size=1)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs):\n",
    "    processed_inputs = []\n",
    "    \n",
    "    for data in inputs:\n",
    "        S = librosa.feature.melspectrogram(y=data, sr=44100)\n",
    "        S_db = librosa.core.power_to_db(S)\n",
    "        processed_inputs.append(torch.from_numpy(S_db))\n",
    "\n",
    "    inputs = torch.stack(processed_inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.unsqueeze(inputs, 1)\n",
    "        output = model(inputs)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "132096\n",
      "88200\n",
      "132300\n",
      "132300\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "generated_true_sample = generate_sample(\"new_recording.wav\")\n",
    "generated_true_sample = generated_true_sample.astype(\"float32\")\n",
    "# sf.write(\"sample.wav\", generated_true_sample, 44100)\n",
    "# generated_true_sample = np.expand_dims(generated_true_sample, 0)\n",
    "\n",
    "false_sample, _ = librosa.core.load(\"false_sample.mp3\", sr=44100)\n",
    "\n",
    "if len(false_sample) > len(generated_true_sample):\n",
    "    false_sample = false_sample[:len(generated_true_sample)]\n",
    "else:\n",
    "    false_sample = np.pad(false_sample, (0, len(generated_true_sample) - len(false_sample)))\n",
    "# false_sample = np.expand_dims(false_sample, 0)\n",
    "\n",
    "print(len(generated_true_sample))\n",
    "print(len(false_sample))\n",
    "\n",
    "\n",
    "output = predict(model, [false_sample, generated_true_sample])\n",
    "torch.round(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9a9b5adc82776b1b2f2584c553d2c8333e90887052c5945a660eb3ca77e2a1ee"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}